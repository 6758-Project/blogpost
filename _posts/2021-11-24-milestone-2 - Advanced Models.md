---
layout: post
title: NHL Data Science Project - Milestone 2 - Advanced Models
---


# Advanced Models

## Q1: XGBoost Trained on Distance and Angle Features



Add the corresponding curves to the four figures in your blog post. Briefly (few sentences) discuss your training/validation setup, and compare the results to the Logistic Regression baseline. Include a link to the relevant comet.ml entry for this experiment, but you do not need to log this model to the model registry.





![XGBoost Baseline](/Images/M2_AM_Q2_XGBoost_Baseline.png)

### Comet.ml link:
Experiment entry: 







## Q2: XGBoost Trained on New Features and Hyperparameter Tuning




In your blog post, discuss your hyperparameter tuning setup, and include figures to substantiate your choice of hyperparameters. For example, you could select appropriate metrics and do a grid search with cross validation. Once tuned, include curves corresponding to the best model to the four figures in your blog post, and briefly compare the results to the XGBoost baseline. Include a link to the relevant comet.ml entry for this experiment, and log this model to the model registry.

![XGBoost Hyperparameter Tuned](/Images/M2_AM_Q2_XGBoost_Hyper_Tuned.png)

### Comet.ml links:
XGBoost classifier, trained on new features and hyperparameter tuning: [TBD](https://www.comet.ml/tim-k-lee/model-registry/TBD)




## Q3: XGBoost Trained on Optimal Feature Set


Discuss the feature selection strategies that you tried, and what was the most optimal set of features that you came up with. Include some figures to substantiate your claims. Once youâ€™ve found the optimal set of features via hyperparameter tuning/cross validation, if the feature set is different than what was used for Q2 of this section, include curves corresponding to the best model to the four figures in your blog post, and briefly compare the results to the XGBoost baseline. Include a link to the relevant comet.ml entry for this experiment, and log this model to the model registry.


![XGBoost Optimal](/Images/M2_AM_Q2_XGBoost_Hyper_Optimal.png)

### Comet.ml link:
XGBoost classifier, trained on optimal feature set: [TBD](https://www.comet.ml/tim-k-lee/model-registry/TBD)










